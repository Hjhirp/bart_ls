{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import os\n",
    "from fairseq import checkpoint_utils\n",
    "import fairseq\n",
    "\n",
    "\n",
    "\n",
    "checkpoint_path = '/data/home/xwhan/fairseq-py/checkpoints/bart.large/model.pt'\n",
    "state = checkpoint_utils.load_checkpoint_to_cpu(checkpoint_path)\n",
    "state['cfg'].task.data = '/datasets01/bookwiki_CC-NEWS_openwebtext_stories-mmap2-bin/121219/bookwiki_CC-NEWS_openwebtext_stories-mmap2-bin'\n",
    "task = fairseq.tasks.setup_task(state['cfg'].task)\n",
    "\n",
    "# print(state['cfg'].model)\n",
    "bart = task.build_model(state['cfg'].model)\n",
    "bart.load_state_dict(state['model'], strict=True, model_cfg=state['cfg'].model)\n",
    "\n",
    "bart_cfg = state['cfg']\n",
    "bart_cfg.model.max_source_positions = 1024 * 16\n",
    "bart_cfg.model.alibi = True\n",
    "long_model = task.build_model(bart_cfg.model)\n",
    "\n",
    "print(long_model)\n",
    "\n",
    "# ##### encoder staff #####\n",
    "# # 1. embed_tokens and layernorm_embedding\n",
    "# long_model.encoder.embed_tokens.load_state_dict(bart.encoder.embed_tokens.state_dict())\n",
    "# long_model.encoder.layernorm_embedding.load_state_dict(bart.encoder.layernorm_embedding.state_dict())\n",
    "\n",
    "# # 2. attention layers\n",
    "# long_model.encoder.layers.load_state_dict(bart.encoder.layers.state_dict(), strict=True)\n",
    "\n",
    "# # 3. embed_positions, longer\n",
    "# pos_limit, _ = bart.encoder.embed_positions.weight.shape\n",
    "# new_pos_limit, embed_dim = long_model.encoder.embed_positions.weight.shape\n",
    "# new_pos_embed = bart.encoder.embed_positions.weight.new_empty(new_pos_limit, embed_dim)\n",
    "# step = pos_limit - 2\n",
    "# for start in range(2, new_pos_limit, step):\n",
    "#     new_pos_embed[start:start+step] = bart.encoder.embed_positions.weight[2:]\n",
    "# long_model.encoder.embed_positions.weight.data = new_pos_embed\n",
    "\n",
    "# ##### decoder staff #####\n",
    "# long_model.decoder.load_state_dict(bart.decoder.state_dict())\n",
    "\n",
    "# save_path = '/data/home/xwhan/fairseq-py/checkpoints/bart.large.block16k'\n",
    "# task.dictionary.save(os.path.join(save_path, 'dict.txt'))\n",
    "# state['args'] = bart_cfg.model\n",
    "# state['model'] = long_model.state_dict()\n",
    "# print(state.keys())\n",
    "# if 'criterion' in state:\n",
    "#     del state['criterion']\n",
    "# state['extra_state'] = {\"epoch\": 0}\n",
    "# state['last_optimizer_state'] = None\n",
    "# torch.save(state, os.path.join(save_path, 'model.pt'))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f27bbda8f97faa009cde89c13fb49b5ff9a0c2e33abf17d1eb4c9179270c4a3d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('fairseq-20210525-py38': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
