{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fairseq.tasks.denoising import DenoisingTask\n",
    "from fairseq.tasks.translation import TranslationTask\n",
    "from fairseq.dataclass.utils import convert_namespace_to_omegaconf\n",
    "import torch\n",
    "import os\n",
    "from fairseq import checkpoint_utils\n",
    "\n",
    "# load pretrained bart-large model\n",
    "checkpoint_path = \"/data/home/xwhan/fairseq-py/checkpoints/bart.large\"\n",
    "\n",
    "# bart = models[0]\n",
    "dictionary = DenoisingTask.load_dictionary(os.path.join(checkpoint_path, 'dict.txt'))\n",
    "state = torch.load(os.path.join(checkpoint_path, 'model.pt'), map_location=torch.device('cpu'))\n",
    "bart_cfg = convert_namespace_to_omegaconf(state['args'])\n",
    "task = DenoisingTask(state['args'], dictionary)\n",
    "bart = task.build_model(bart_cfg.model)\n",
    "bart.load_state_dict(state['model'], strict=True, model_cfg=bart_cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17156\n"
     ]
    }
   ],
   "source": [
    "# build sparse transformer\n",
    "from fairseq.tasks.long_denoising import LongDenoisingTask\n",
    "\n",
    "model_args = state['args']\n",
    "model_args.use_xformers = True\n",
    "model_args.attention_name = 'block_noglobal'\n",
    "model_args.xformer_config = '{\"window_size\": 1024}'\n",
    "model_args.max_source_positions = 1024 * 16\n",
    "model_args.max_target_positions = 1024\n",
    "model_args.mean_noise_span_length = 10\n",
    "model_args.noise_density = 0.05\n",
    "\n",
    "\n",
    "## need these steps such that the models can add sentinel tokens to its vocab\n",
    "def compute_input_and_target_lengths(inputs_length, noise_density, mean_noise_span_length):\n",
    "\n",
    "    def _tokens_length_to_inputs_length_targets_length(tokens_length):\n",
    "        num_noise_tokens = int(round(tokens_length * noise_density))\n",
    "        num_nonnoise_tokens = tokens_length - num_noise_tokens\n",
    "        num_noise_spans = int(round(num_noise_tokens / mean_noise_span_length))\n",
    "\n",
    "        # @xwhan leave aside EOS token at this point\n",
    "        _input_length = num_nonnoise_tokens + num_noise_spans\n",
    "        _output_length = num_noise_tokens + num_noise_spans\n",
    "        return _input_length, _output_length\n",
    "\n",
    "    tokens_length = inputs_length\n",
    "\n",
    "    while _tokens_length_to_inputs_length_targets_length(tokens_length + 1)[0] <= inputs_length:\n",
    "        tokens_length += 1\n",
    "\n",
    "    inputs_length, targets_length = _tokens_length_to_inputs_length_targets_length(tokens_length)\n",
    "\n",
    "    # minor hack to get the targets length to be equal to inputs length\n",
    "    # which is more likely to have been set to a nice round number.\n",
    "    if noise_density == 0.5 and targets_length > inputs_length:\n",
    "        tokens_length -= 1\n",
    "        targets_length -= 1\n",
    "    return tokens_length, targets_length\n",
    "\n",
    "\n",
    "# these parameters are needed for the task to tell how many sentinel tokens are needed\n",
    "tokens_per_sample, _ = compute_input_and_target_lengths(model_args.max_source_positions - 2, model_args.noise_density, model_args.mean_noise_span_length)\n",
    "model_args.tokens_per_sample = tokens_per_sample + 2\n",
    "print(model_args.tokens_per_sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50264"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.index('<mask>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old embedding matrix size 50265\n",
      "50351\n"
     ]
    }
   ],
   "source": [
    "task = LongDenoisingTask(model_args, dictionary)\n",
    "\n",
    "long_cfg = convert_namespace_to_omegaconf(model_args)\n",
    "long_model = task.build_model(long_cfg.model)\n",
    "\n",
    "##### encoder staff #####\n",
    "\n",
    "# 1. embed_tokens and layernorm_embedding\n",
    "vocab_size, _ = bart.encoder.embed_tokens.weight.shape\n",
    "new_vocab_size, embed_dim = long_model.encoder.embed_tokens.weight.shape\n",
    "print('old embedding matrix size', vocab_size)\n",
    "print('new embedding matrix size', new_vocab_size)\n",
    "# how should we initialize these sentinel embeddings\n",
    "new_embed_tokens = bart.encoder.embed_tokens.weight.new_empty(new_vocab_size, embed_dim)\n",
    "new_embed_tokens[:vocab_size] = bart.encoder.embed_tokens.weight\n",
    "for idx in range(vocab_size, new_vocab_size):\n",
    "    new_embed_tokens[idx] = bart.encoder.embed_tokens.weight[-1] # initialize with <mask>\n",
    "long_model.encoder.embed_tokens.weight.data = new_embed_tokens\n",
    "long_model.encoder.layernorm_embedding.load_state_dict(bart.encoder.layernorm_embedding.state_dict())\n",
    "\n",
    "# 2. attention layers\n",
    "long_model.encoder.layers.load_state_dict(bart.encoder.layers.state_dict(), strict=False)\n",
    "\n",
    "# 3. embed_positions, longer\n",
    "pos_limit, _ = bart.encoder.embed_positions.weight.shape\n",
    "new_pos_limit, embed_dim = long_model.encoder.embed_positions.weight.shape\n",
    "new_pos_embed = bart.encoder.embed_positions.weight.new_empty(new_pos_limit, embed_dim)\n",
    "step = pos_limit - 2\n",
    "for start in range(2, new_pos_limit, step):\n",
    "    new_pos_embed[start:start+step] = bart.encoder.embed_positions.weight[2:]\n",
    "long_model.encoder.embed_positions.weight.data = new_pos_embed\n",
    "\n",
    "##### decoder staff #####\n",
    "long_model.decoder.layernorm_embedding.load_state_dict(bart.decoder.layernorm_embedding.state_dict())\n",
    "\n",
    "# 2. embed_positions, longer\n",
    "long_model.decoder.embed_positions.load_state_dict(bart.decoder.embed_positions.state_dict())\n",
    "\n",
    "# 3. attention layers\n",
    "long_model.decoder.layers.load_state_dict(bart.decoder.layers.state_dict(), strict=True)\n",
    "\n",
    "# 4. output_projection\n",
    "# no need to copy as they are tied with encoder's embeds\n",
    "\n",
    "save_path = '/data/home/xwhan/fairseq-py/checkpoints/bart.long.pretrain.block'\n",
    "dictionary.save(os.path.join(save_path, 'dict.txt'))\n",
    "state['args'] = model_args\n",
    "state['model'] = long_model.state_dict()\n",
    "torch.save(state, os.path.join(save_path, 'model.pt'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f27bbda8f97faa009cde89c13fb49b5ff9a0c2e33abf17d1eb4c9179270c4a3d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('fairseq-20210525-py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
